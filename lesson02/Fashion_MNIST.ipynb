{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "ILIhIVEOvdrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the GPU is available use it for the computation otherwise use the CPU."
      ],
      "metadata": {
        "id": "DyYwZ_OGe3NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "bMh0L6ltexMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST\n",
        "\n",
        "The Fashion MNIST dataset contains thousands of grayscale images of different types of clothes. There are ten distinct categories encoded into numbers 0 - 10:\n",
        "\n",
        "0   T-shirt/top\n",
        "\n",
        "1\tTrouser\n",
        "\n",
        "2\tPullover\n",
        "\n",
        "3\tDress\n",
        "\n",
        "4\tCoat\n",
        "\n",
        "5\tSandal\n",
        "\n",
        "6\tShirt\n",
        "\n",
        "7\tSneaker\n",
        "\n",
        "8\tBag\n",
        "\n",
        "9\tAnkle boot"
      ],
      "metadata": {
        "id": "0D_mzjVbwWas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset"
      ],
      "metadata": {
        "id": "vyFWnSrWwL4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets.FashionMNIST(\"./data\", download=True, train=True, transform=transforms.Compose([transforms.ToTensor(), torch.flatten]))\n",
        "test_set = datasets.FashionMNIST(\"./data\", download=True, train=False, transform=transforms.Compose([transforms.ToTensor(), torch.flatten]))"
      ],
      "metadata": {
        "id": "dlIxrYjiuZ34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to feed the dataset into our network in batches of size 64 as the dataset is too big to be used all at once."
      ],
      "metadata": {
        "id": "klk3aXlp1Ha3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoaders.from_dsets(train_set, test_set, bs=128)"
      ],
      "metadata": {
        "id": "bcqfZoPQveqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the mini batch you'll get from the train data loader:"
      ],
      "metadata": {
        "id": "l9ChS34J1Y2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(data_loader.train))\n",
        "x.size(), y.size()"
      ],
      "metadata": {
        "id": "YGw_09jQ0XlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_set)"
      ],
      "metadata": {
        "id": "P8cWcL0bwP3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_set)"
      ],
      "metadata": {
        "id": "M6XnjvAnwiqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0][0].size()"
      ],
      "metadata": {
        "id": "e5peZemYyDOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "idxwfOFFxG-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot some images from our dataset"
      ],
      "metadata": {
        "id": "4PUD1U1ixLqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(x, title = \"\"):\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(torch.reshape(x, (28,28)), cmap=plt.cm.binary)\n",
        "  plt.xlabel(title)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(0, 160, 10):\n",
        "  plt.subplot(4, 4, i // 10 + 1)\n",
        "  plot_image(train_set[i][0], clothes_labels[train_set[i][1]])"
      ],
      "metadata": {
        "id": "hjdCMRa1xIpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense NN\n",
        "\n",
        "Let's try to apply dense neural network (we talked about it in the previous lesson) to our images.\n",
        "\n",
        "All layers are Linear - the classic fully-connected neural network layers.\n",
        "\n",
        "- The hidden layers will have 128 and 64 units and use the ReLU activation function.\n",
        "- The output layer will have 10 units, corresponding to the 10 classes, and use softmax function.\n",
        "\n",
        "The general convention for Pytorch network classes is that you create all your layers in the constructor, and then lay out their relationship in the `forward()` method."
      ],
      "metadata": {
        "id": "JT3fTLXYzjrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, image_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(image_size, _) # TODO nn.Linear(n_input_neurons, n_output_neurons)\n",
        "        self.fc2 = nn.Linear(_, _) # TODO\n",
        "        self.fc3 = nn.Linear(_, _) # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.softmax(self.fc3(x), dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ixthf2UXx6Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(image_size=_) # TODO\n",
        "model.to(device)\n",
        "model"
      ],
      "metadata": {
        "id": "zYPEUmEE7cU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "HABTozDe7lp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate\n",
        "lr = 5e-4\n",
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "AJolB7Bs7oMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather then setting up the model optimization in Pytorch, we are going to use fastai's Learner object. (By default, it uses the Adam optimizer.)"
      ],
      "metadata": {
        "id": "Gj7nVMhn7v2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(data_loader, model, loss_func=loss_func, metrics=accuracy)"
      ],
      "metadata": {
        "id": "bH5iSuCz7wj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(n_epoch=3, lr=lr)"
      ],
      "metadata": {
        "id": "5y9HyJAb8ZKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_loss()"
      ],
      "metadata": {
        "id": "Q27CRjguE7Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wUmF0hqhFbNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN\n",
        "\n",
        "Let's try a different architecture, this time a Convolutional Neural Network"
      ],
      "metadata": {
        "id": "ZLP4gr7IFc0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data in different format"
      ],
      "metadata": {
        "id": "rtEiE0HeRNCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets.FashionMNIST(\"./data\", download=True, train=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "test_set = datasets.FashionMNIST(\"./data\", download=True, train=False, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "data_loader = DataLoaders.from_dsets(train_set, test_set, bs=128)"
      ],
      "metadata": {
        "id": "uPHvqSo1RJUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(in_features=24*24*64, out_features=128)\n",
        "        self.drop = nn.Dropout(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.flat(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        x = F.softmax(self.fc2(x), dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8vpdNOICOLIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "model.to(device)\n",
        "model"
      ],
      "metadata": {
        "id": "FLJBGqJIReBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "w8_NGUYQReBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate\n",
        "lr = 5e-4\n",
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "smzM33E7ReBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather then setting up the model optimization in Pytorch, we are going to use fastai's Learner object. (By default, it uses the Adam optimizer.)"
      ],
      "metadata": {
        "id": "0ClEGE9hReBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(data_loader, model, loss_func=loss_func, metrics=accuracy)"
      ],
      "metadata": {
        "id": "VW014wMWReBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(3, lr)"
      ],
      "metadata": {
        "id": "S7dlfhdZReCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_loss()"
      ],
      "metadata": {
        "id": "1L9_l2iBReCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_image(test_set[0][0])"
      ],
      "metadata": {
        "id": "GGGre2bjVYqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_labels[torch.argmax(learn.predict(test_set[0])[0])]"
      ],
      "metadata": {
        "id": "FyLoF13USJmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}