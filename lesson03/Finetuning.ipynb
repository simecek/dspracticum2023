{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simecek/dspracticum2023/blob/main/lesson03/Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "IJUJg1QkngXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from fastai.vision.all import *"
      ],
      "metadata": {
        "id": "fobRytGUpl1W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "3cN0_inMqMc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvNeXt\n"
      ],
      "metadata": {
        "id": "AMaMDWFc9fiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"convnext_tiny.fb_in22k\"\n",
        "convnext = timm.create_model(model_name, pretrained=True).to(device)"
      ],
      "metadata": {
        "id": "7_kRssOEpQZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can also list all models available or search through wildcard\n",
        "# timm.list_models('*convnext*')"
      ],
      "metadata": {
        "id": "zJflwrYf4E1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(convnext, (3, 256, 256))"
      ],
      "metadata": {
        "id": "5Pp4Of2atdZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### download label mapping for the model"
      ],
      "metadata": {
        "id": "7NNyqm0u9qNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/convnext/label_to_words.json\n",
        "imagenet_labels = json.load(open('label_to_words.json'))"
      ],
      "metadata": {
        "id": "mmvWG8mIvNId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### download random image and predict it via ConvNeXt"
      ],
      "metadata": {
        "id": "zH7iboEV9uv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --output-document=test.jpeg https://upload.wikimedia.org/wikipedia/commons/d/d7/Squirrel_in_Seurasaari_autumn.JPG\n",
        "img = PIL.Image.open('test.jpeg')\n",
        "\n",
        "# Define transforms for image\n",
        "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "\n",
        "transformations = [\n",
        "              transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC), # resize smaller edge to 256\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
        "              ]\n",
        "\n",
        "transformations = transforms.Compose(transformations)\n",
        "\n",
        "img_tensor = transformations(img).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "CLbf4Uvn0rDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict label for our image"
      ],
      "metadata": {
        "id": "WJEfkfwN0FJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.softmax(convnext(img_tensor), dim=1)\n",
        "top5 = torch.topk(output, k=5)\n",
        "top5_prob = top5.values[0]\n",
        "top5_indices = top5.indices[0]\n",
        "\n",
        "for i in range(5):\n",
        "    labels = imagenet_labels[str(int(top5_indices[i]))]\n",
        "    prob = \"{:.2f}%\".format(float(top5_prob[i])*100)\n",
        "    print(labels, prob)\n",
        "\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "vvvY7iycvABq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5Oh2fMBqTnBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our custom dataset - Tom & Jerry\n",
        "\n",
        "https://www.kaggle.com/datasets/balabaskar/tom-and-jerry-image-classification\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0vWQPDZV9NqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = 'balabaskar/tom-and-jerry-image-classification'\n",
        "ZIP_PATH = './tom-and-jerry-image-classification.zip'\n",
        "IMAGES_PATH = './tom_and_jerry/tom_and_jerry'"
      ],
      "metadata": {
        "id": "pvY5z0qjXK24"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'evaklimentov'\n",
        "os.environ['KAGGLE_KEY'] = 'c3161c890c8b21e1e5cba18c9a7505c0'\n",
        "\n",
        "!kaggle datasets download -d {DATASET} -p ./"
      ],
      "metadata": {
        "id": "a7Zv0R2uVq_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ],
      "metadata": {
        "id": "EkdN3jjXXhx4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=Resize(256, method='squish'))\n",
        "\n",
        "dls = images.dataloaders(IMAGES_PATH, bs=64)\n",
        "\n",
        "dls.show_batch(max_n=6)"
      ],
      "metadata": {
        "id": "ZsGiQkIh1B5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dls.train.dataset))\n",
        "print(len(dls.valid.dataset))"
      ],
      "metadata": {
        "id": "hP37VgND_NgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load ConvNeXt model and fine-tune it"
      ],
      "metadata": {
        "id": "MiLSDaM7z693"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = vision_learner(dls, convnext_tiny, metrics=accuracy)\n",
        "learn.fine_tune(3, freeze_epochs=1)"
      ],
      "metadata": {
        "id": "VNvakLIc1bd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## See how our model performs:\n"
      ],
      "metadata": {
        "id": "7XdMdyXwvTFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix(figsize=(8,8), dpi=80)"
      ],
      "metadata": {
        "id": "LVjcnhRJnm_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### what is hard to predic?"
      ],
      "metadata": {
        "id": "o-bZEGge0cSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interp.plot_top_losses(8, figsize=(13,13))"
      ],
      "metadata": {
        "id": "tmCBTSqynp6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlUSZNU_NI4R"
      },
      "source": [
        "## Predict a new image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItkEQfRcNORv"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM9DM3N8NzQ0"
      },
      "source": [
        "img = PILImage.create(list(uploaded.values())[0])\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii5nW-1nOavg"
      },
      "source": [
        "pred,pred_idx,probs = learn.predict(img)\n",
        "pred,pred_idx,probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation"
      ],
      "metadata": {
        "id": "bHdtoERZ0gMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "use image transformations from https://docs.fast.ai/vision.augment.html"
      ],
      "metadata": {
        "id": "SUlx8UvBnPvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfms = [] # TODO\n",
        "\n",
        "dls = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=[Resize(256, method='squish')],\n",
        "    batch_tfms=tfms\n",
        ").dataloaders(IMAGES_PATH, bs=64)\n",
        "\n",
        "dls.show_batch(max_n=6, unique=True)"
      ],
      "metadata": {
        "id": "i0BO419LA_fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = vision_learner(dls, convnext_tiny, metrics=accuracy)\n",
        "learn.fine_tune(3, freeze_epochs=1)"
      ],
      "metadata": {
        "id": "70YRNqMuexX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diving into `fine_tune`"
      ],
      "metadata": {
        "id": "vmjyeZXP0kRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's uncover what's inside:\n",
        "\n",
        "`fine_tune` = `learn.freeze(), learn.fit_one_cycle(), learn.unfreeze(), learn.fit_one_cycle()`"
      ],
      "metadata": {
        "id": "vaSJODUQATgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "but at first, let's have a look at what happens with the learning rate during the training we performed"
      ],
      "metadata": {
        "id": "Z67czwAc7Ejk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_sched(keys='lr')"
      ],
      "metadata": {
        "id": "PNyU1WW7tSEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = vision_learner(dls, convnext_tiny, metrics=accuracy)\n",
        "learn.freeze()\n",
        "learn.summary()"
      ],
      "metadata": {
        "id": "5BHf-IGJ7DdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(1, 0.5)"
      ],
      "metadata": {
        "id": "zTRiGZieqzpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit(3, 0.5)"
      ],
      "metadata": {
        "id": "sZW3GorE4y2H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}