**Date**: Oct 16, 2023

**Slides**: https://docs.google.com/presentation/d/1EWXoiwxVasnV8xedDn58p0f1gsJ__Wh8s0jUQvtCxEY/edit?usp=sharing

* Tokenizers
* Embeddings
* Transformers


**Practical exercises**:

* [Live coding](https://colab.research.google.com/drive/1iNnZF1hi3bERZn1Shr5ufP_0_2Jr0YVX?usp=sharing) in Colab during the lecture
* [Finetuning the transformer for text classification](https://colab.research.google.com/drive/13ffvt9kK8smGfVjlwB2Qbwf_njmFxMa-?usp=sharing)


**Assignment 05** (due to Oct 23, 8:00):
  1. Find a dataset to demonstrate embeddings techniques, it might be a collection of texts, images or combination of both.
  1. You can try searching for the most similar image / text, visualization with PCA, clustering or superfast classification based on embeddings. Or even something we did not mentioned.
  1. Deploy your model as app in HF Spaces (if you did not succeed, send us at least link to GitHub repo)



