{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification\n",
        "\n",
        "We will use the [distilled version of the BERT base model](https://huggingface.co/distilbert-base-uncased) on a [dataset with news articles](https://huggingface.co/datasets/ag_news) from HuggingFace.\n",
        "\n",
        "The dataset consists of 120000 training and 7600 testing samples which can be divided into 4 classes: `World` (0), `Sports` (1), `Business` (2), and `Sci/Tech` (3)"
      ],
      "metadata": {
        "id": "SwTGgyHIAwgp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0I_zPlvllrD"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers[torch] datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = 'ag_news'\n",
        "NUM_LABELS = 4\n",
        "MODEL = 'distilbert-base-uncased'"
      ],
      "metadata": {
        "id": "0S5q6jidj_0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset with news articles:"
      ],
      "metadata": {
        "id": "G4WVcjkMifA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOe41WLYDIka"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(DATASET)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the format of one sample from our dataset:"
      ],
      "metadata": {
        "id": "6AU5H5J9iTiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "id": "23rHNPjtlPR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check whether our dataset is balanced (get the number of samples from each class):"
      ],
      "metadata": {
        "id": "UXi5tnDnibS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def check_class_balance(class_labels):\n",
        "  values, counts = np.unique(class_labels, return_counts=True)\n",
        "  return values, counts\n",
        "\n",
        "check_class_balance(dataset['train']['label'])"
      ],
      "metadata": {
        "id": "JH2vHaLLibqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the tokenizer and have a look at it's special tokens:"
      ],
      "metadata": {
        "id": "SWSDfz0oijPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ScT_VSKDSAd"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*What do these tokens mean?*"
      ],
      "metadata": {
        "id": "n3u2cT8Bnksj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check what exactly does the tokenizer return (when applied on one sample):"
      ],
      "metadata": {
        "id": "0wAk6nRbkLMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_sample_text = dataset['train'][0]['text']\n",
        "first_sample_text"
      ],
      "metadata": {
        "id": "fBYs0u2lm3a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# hint: use tokenizer.tokenize(), tokenizer.convert_tokens_to_ids(), tokenizer.decode()"
      ],
      "metadata": {
        "id": "ftGWS8PKmoo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare it to what is returned we when use the `preprocess_function`:\n",
        "\n"
      ],
      "metadata": {
        "id": "CIYpTC1Yo6sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "  # https://huggingface.co/docs/transformers/pad_truncation\n",
        "  # truncation=True and padding='max_length' -> pads sequences with [PAD] token to given max sequence length\n",
        "  return tokenizer(examples['text'], truncation=True, padding='max_length', return_tensors='pt')\n",
        "\n",
        "first_sample_tokenized = preprocess_function(dataset['train'][0])\n",
        "first_sample_tokenized"
      ],
      "metadata": {
        "id": "JZWdCMiOj7L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess more samples from our dataset at once:"
      ],
      "metadata": {
        "id": "NhBaRCqujtyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training on the whole dataset would take more than 5 hours :(\n",
        "# train_dataset = dataset['train'].map(preprocess_function, batched=True)\n",
        "# test_dataset = dataset['test'].map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset = dataset['train'].shuffle(seed=42).select(range(2500)).map(preprocess_function, batched=True)\n",
        "test_dataset = dataset['test'].shuffle(seed=42).select(range(500)).map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "fdcnYHVVrMXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_class_balance(train_dataset['label'])"
      ],
      "metadata": {
        "id": "ZcGD5IeKI7ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_class_balance(test_dataset['label'])"
      ],
      "metadata": {
        "id": "5lcnnOqaJHhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model:"
      ],
      "metadata": {
        "id": "drOkfES-io3N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxsAOhF5FESf"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "id2label = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n",
        "label2id = {'World': 0, 'Sports': 1, 'Business': 2, 'Sci/Tech': 3}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL,\n",
        "                                                           num_labels=NUM_LABELS,\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define evaluation metrics and train our model:"
      ],
      "metadata": {
        "id": "EkhyMYYAirC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsM6VR9fFNfa"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return {'accuracy': accuracy_score(p.label_ids, preds)}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=16,\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.0\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the trained model to get prediction for some random sentence of your choice using `pipeline`:\n",
        "\n",
        "https://huggingface.co/docs/transformers/main_classes/pipelines\n"
      ],
      "metadata": {
        "id": "3w0Zbv8Pa1zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "# TODO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhzowVVzCEcU",
        "outputId": "3d25e036-4bf7-4bbb-f1ec-5dbb5ca389a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x7faf29ae2e30>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens when we try to predict the label of a sentence that actually belongs to a class that wasn't in our data?\n",
        "\n",
        "Is it correct behaviour?"
      ],
      "metadata": {
        "id": "ZJv2GOOVPPEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can we improve the performance of our model?"
      ],
      "metadata": {
        "id": "VmkfssIcizPv"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}